{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ETL pipeline project to extract top banks data and sort top 10 banks on their market cap in USD and then transform to GBP, EUR and INR as well, in accordance with the exchange rate information**\n",
        "\n",
        "Following is a demonstration of:\n",
        "\n",
        "\n",
        "*   Using website **api** and **python requests library** to **get** information from *archive.org* website\n",
        "*   Use **BeautifulSoup** to parse the file\n",
        "*   Then **transform** the data to the required format\n",
        "*   Then save it as **CSV** and **database**"
      ],
      "metadata": {
        "id": "6GyjD3UXUcyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries and packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "import lxml"
      ],
      "metadata": {
        "id": "9yz36vzjUdVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preliminaries\n",
        "def preliminaries():\n",
        "  global url, exchange_rate_url, table_attribs, final_table_attribs, csv_path, db_name, db_table\n",
        "  url = 'https://web.archive.org/web/20230908091635 /https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
        "  exchange_rate_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
        "  table_attribs = [\"Name\", \"MC_USD_Billion\"]\n",
        "  final_table_attribs = [\"Name\", \"MC_USD_Billion\", \"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"]\n",
        "  csv_path = './Largest_banks_data.csv'\n",
        "  db_name = 'Banks.db'\n",
        "  db_table = 'Largest_banks'\n"
      ],
      "metadata": {
        "id": "iT0QUmudVd4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging process\n",
        "\n",
        "def log_progress(message):\n",
        "  timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
        "  now = datetime.now()\n",
        "  timestamp = now.strftime(timestamp_format)\n",
        "  with open('logfile.txt', 'a') as f:\n",
        "    f.write(timestamp + ':' + message + '\\n')\n"
      ],
      "metadata": {
        "id": "13FwjD9Xed2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction of data from url\n",
        "\n",
        "def extract(url):\n",
        "  page = requests.get(url).text\n",
        "  data = BeautifulSoup(page, 'html.parser')\n",
        "  df = pd.DataFrame(columns=table_attribs)\n",
        "  tables = data.find_all('tbody')\n",
        "  rows = tables[0].find_all('tr')\n",
        "\n",
        "  for row in rows:\n",
        "    col = row.find_all('td')\n",
        "    if len(col) != 0:\n",
        "      links = col[1].find_all('a')\n",
        "      if len(links) != 0:\n",
        "        data_dict = {'Name' : links[-1].text,\n",
        "                     'MC_USD_Billion' : col[2].text}\n",
        "        df1 = pd.DataFrame(data_dict, index=[0])\n",
        "        df = pd.concat([df, df1], ignore_index=True)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "bWUljudefHv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation of the data\n",
        "\n",
        "def transform(df):\n",
        "  exchange_rate = pd.read_csv(exchange_rate_url, index_col=0)\n",
        "  df[\"MC_GBP_Billion\"] = df[\"MC_USD_Billion\"].astype(float) * exchange_rate.loc[\"GBP\", \"Rate\"]\n",
        "  df[\"MC_EUR_Billion\"] = df[\"MC_USD_Billion\"].astype(float) * exchange_rate.loc[\"EUR\", \"Rate\"]\n",
        "  df[\"MC_INR_Billion\"] = df[\"MC_USD_Billion\"].astype(float) * exchange_rate.loc[\"INR\", \"Rate\"]\n",
        "  return df"
      ],
      "metadata": {
        "id": "kzc9sSuigrVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "\n",
        "def to_csv(df, csv_path):\n",
        "  df.to_csv(csv_path)\n",
        "\n",
        "def to_sql(df, db_name, db_table):\n",
        "  connection = sqlite3.connect(db_name)\n",
        "  df.to_sql(db_table, connection, if_exists='replace', index=False)"
      ],
      "metadata": {
        "id": "yBHZ6fHAmpES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying db\n",
        "\n",
        "def run_query(query_statement, db_name):\n",
        "  connection = sqlite3.connect(db_name)\n",
        "  query_output = pd.read_sql(query_statement, connection)\n",
        "  print(query_output)\n",
        "  return query_output"
      ],
      "metadata": {
        "id": "7gyhgBWbp3F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function calls\n",
        "\n",
        "preliminaries()\n",
        "log_progress('Preliminaries complete. Initiating ETL process')\n",
        "df = extract(url)\n",
        "log_progress('Data extraction complete. Initiating Transformation process')\n",
        "df = transform(df)\n",
        "log_progress('Data transformation complete. Initiating loading process')\n",
        "to_csv(df, csv_path)\n",
        "to_sql(df, db_name, db_table)\n",
        "log_progress('Data saved to CSV file and into Banks.db')\n",
        "query_statement_1 = 'SELECT * FROM Largest_banks'\n",
        "query_statement_2 = 'SELECT AVG(MC_GBP_Billion) FROM Largest_banks'\n",
        "query_statement_3 = 'SELECT Name from Largest_banks LIMIT 5'\n",
        "run_query(query_statement_1, db_name)\n",
        "run_query(query_statement_2, db_name)\n",
        "run_query(query_statement_3, db_name)\n",
        "log_progress('Process Complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkWB5B8AqZah",
        "outputId": "709a8633-b33e-4a60-9f63-cb56bb9a0b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Name\n",
            "0                           JPMorgan Chase\n",
            "1                          Bank of America\n",
            "2  Industrial and Commercial Bank of China\n",
            "3               Agricultural Bank of China\n",
            "4                                HDFC Bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrUUw9lHrKg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}